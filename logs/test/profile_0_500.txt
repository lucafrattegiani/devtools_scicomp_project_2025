Timer unit: 1e-06 s

Total time: 0.944507 s
File: /u/l/lfratteg/upt_project/models/approximator.py
Function: Approximator.forward at line 76

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    76                                               @profile
    77                                               def forward(self, x: torch.Tensor) -> torch.Tensor:
    78                                                   r"""
    79                                                   Apply the Transformer stack.
    80                                           
    81                                                   Parameters
    82                                                   ----------
    83                                                   x : torch.Tensor
    84                                                       Input tokens of shape ``(B, N, dim)``.
    85                                           
    86                                                   Returns
    87                                                   -------
    88                                                   torch.Tensor
    89                                                       Output tokens of shape ``(B, N, dim)``.
    90                                           
    91                                                   Raises
    92                                                   ------
    93                                                   AssertionError
    94                                                       If ``x`` is not rank-3.
    95                                                   """
    96       189        190.1      1.0      0.0          assert x.ndim == 3, f"expected (B, N, dim), got {tuple(x.shape)}"
    97      2457       2734.5      1.1      0.3          for blk in self.blocks:
    98      2268     941526.8    415.1     99.7              x = blk(x)
    99       189         55.5      0.3      0.0          return x

Total time: 0.159503 s
File: /u/l/lfratteg/upt_project/models/decoder.py
Function: PerceiverDecoder.forward at line 120

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   120                                               @profile
   121                                               def forward(self, latent: torch.Tensor, queries: torch.Tensor) -> torch.Tensor:
   122                                                   r"""
   123                                                   Project queries to ``H``, run cross-attention with latent as K/V, refine with FFN, and map to scalars.
   124                                           
   125                                                   Parameters
   126                                                   ----------
   127                                                   latent : torch.Tensor
   128                                                       Latent tokens of shape ``(B, T, H)``.
   129                                                   queries : torch.Tensor
   130                                                       Embedded query tokens of shape ``(B, K, H_q)``.
   131                                           
   132                                                   Returns
   133                                                   -------
   134                                                   torch.Tensor
   135                                                       Scalar predictions per query: ``(B, K, 1)``.
   136                                                   """
   137       189        239.4      1.3      0.2          assert latent.ndim == 3 and queries.ndim == 3, "expected (B,T,H) and (B,K,H_q)"
   138       189        232.7      1.2      0.1          B, T, H_lat = latent.shape
   139       189        113.6      0.6      0.1          Bq, K, H_q = queries.shape
   140       189         65.2      0.3      0.0          assert B == Bq, "batch size mismatch between latent and queries"
   141       189         86.0      0.5      0.1          assert H_lat == self.dim, f"latent width mismatch: got {H_lat}, expected {self.dim}"
   142                                           
   143                                                   # 1) Project queries to model width H
   144       189      22212.4    117.5     13.9          q = self.query_proj(queries)                # (B, K, H)
   145                                           
   146                                                   # 2) Cross-attention: Q attends to latent K=V
   147       189       6469.5     34.2      4.1          qn = self.q_norm(q)
   148       189       5380.2     28.5      3.4          kv = self.kv_norm(latent)
   149       189      75205.3    397.9     47.1          attn_out, _ = self.attn(qn, kv, kv, need_weights=False)   # (B, K, H)
   150       189       6852.5     36.3      4.3          x = q + self.drop(attn_out)                               # residual
   151                                           
   152                                                   # 3) Feed-forward on the query pathway
   153       189      29784.2    157.6     18.7          y = self.ffn(self.ffn_norm(x))
   154       189       2304.6     12.2      1.4          x = x + y                                                 # residual
   155                                           
   156                                                   # 4) Pointwise projection to scalar pressure
   157       189      10490.0     55.5      6.6          out = self.head(x)                                        # (B, K, 1)
   158       189         67.3      0.4      0.0          return out

Total time: 4.87209 s
File: /u/l/lfratteg/upt_project/models/encoder.py
Function: PositionalEmbedding.forward at line 112

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   112                                               @profile
   113                                               def forward(self, positions: torch.Tensor) -> torch.Tensor:
   114                                                   r"""
   115                                                   Embed rescaled 3D positions.
   116                                           
   117                                           
   118                                                   Parameters
   119                                                   ----------
   120                                                   positions : torch.Tensor
   121                                                   Coordinates with shape ``(B, K, 3)`` or ``(K, 3)``.
   122                                           
   123                                           
   124                                                   Returns
   125                                                   -------
   126                                                   torch.Tensor
   127                                                   Positional embeddings of shape ``(B, K, H)``.
   128                                                   """
   129                                                   # Adjust dimensions if one sample only is provided
   130       189        225.8      1.2      0.0          if positions.dim() == 2:  # (K,3) -> (1,K,3)
   131                                                       positions = positions.unsqueeze(0)
   132                                                   
   133                                                   # Rescale
   134       189      46752.9    247.4      1.0          x = self.rescale(positions, hi=self.upper, eps=self.eps)
   135                                           
   136                                                   # Apply positional encoding
   137       189    4825112.9  25529.7     99.0          return self.pe(x)  # Expect (B, K, H)

Total time: 0.116726 s
File: /u/l/lfratteg/upt_project/models/encoder.py
Function: PerceiverEncoder.forward at line 202

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   202                                               @profile
   203                                               def forward(self, tokens: torch.Tensor) -> torch.Tensor:
   204                                                   r"""
   205                                                   Apply one Perceiver pooling step.
   206                                           
   207                                           
   208                                                   Parameters
   209                                                   ----------
   210                                                   tokens : torch.Tensor
   211                                                   Input token set of shape ``(B, K, H)``.
   212                                           
   213                                           
   214                                                   Returns
   215                                                   -------
   216                                                   torch.Tensor
   217                                                   Latent/query tokens of shape ``(B, L, H)``.
   218                                                   """
   219                                           
   220                                                   # Assert valid input dimensions
   221       189        146.2      0.8      0.1          assert tokens.ndim == 3, f"expected (B,K,H), got {tuple(tokens.shape)}"
   222       189        166.0      0.9      0.1          B, K, H = tokens.shape
   223       189        106.1      0.6      0.1          assert H == self.dim, f"hidden_dim mismatch: tokens H={H}, expected {self.dim}"
   224                                           
   225                                                   # Single Perceiver pooling step
   226       189     112950.1    597.6     96.8          Z = self.block(kv=tokens)   # Shape (B, L, H)
   227                                           
   228                                                   # Add grid type embedding
   229       189        646.1      3.4      0.6          if self.type_token is not None:
   230       189       2653.1     14.0      2.3              Z = Z + self.type_token
   231                                           
   232       189         58.8      0.3      0.1          return Z

Total time: 0 s
File: /u/l/lfratteg/upt_project/models/encoder.py
Function: ConvNeXtEncoder.forward at line 346

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   346                                               @profile
   347                                               def forward(self, sdf: torch.Tensor) -> torch.Tensor:
   348                                                   r"""
   349                                                   Encode an SDF grid into grid tokens.
   350                                           
   351                                           
   352                                                   Parameters
   353                                                   ----------
   354                                                   sdf : torch.Tensor
   355                                                   SDF values with shape ``(B, R, R, R)`` where ``R == resolution``.
   356                                           
   357                                           
   358                                                   Returns
   359                                                   -------
   360                                                   torch.Tensor
   361                                                   Grid tokens of shape ``(B, T, H)``.
   362                                                   """
   363                                                   # Validate shape and resolution
   364                                                   assert sdf.ndim == 4, f"expected (B,R,R,R), got {tuple(sdf.shape)}"
   365                                                   B, Rx, Ry, Rz = sdf.shape
   366                                                   assert Rx == Ry == Rz == self.resolution, (
   367                                                       f"expected cubic grid with side={self.resolution}, got {(Rx, Ry, Rz)}"
   368                                                   )
   369                                           
   370                                                   # 1) Add channel axis for 3D convs (channels-first)  
   371                                                   x = sdf.unsqueeze(1)                                   # (B, 1, R, R, R)
   372                                           
   373                                                   # 2) Apply ConvNeXt-v2
   374                                                   x = self.model(x)                                      # (B, H, S, S, S), S=self.out_side
   375                                           
   376                                                   # 3) Flatten spatial grid into tokens
   377                                                   tokens = einops.rearrange(x, "b c d h w -> b (d h w) c")  # (B, T, H), T = S*S*S
   378                                           
   379                                                   # 4) Add grid type embedding (broadcast add)
   380                                                   if self.type_token is not None:
   381                                                       tokens = tokens + self.type_token                   # (B, T, H)
   382                                           
   383                                                   return tokens

Total time: 0 s
File: /u/l/lfratteg/upt_project/models/model.py
Function: UPTSDF.forward at line 118

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   118                                               @profile
   119                                               def forward(self, mesh_pos: torch.Tensor, sdf: torch.Tensor) -> torch.Tensor:
   120                                                   # Mesh branch: pos-embed (B,P,H) → Perceiver (B,Lm,H)
   121                                                   q_mesh = self.mesh_pos_emb(mesh_pos)            # (B,P,H)
   122                                                   mesh_tokens = self.mesh_perceiver(q_mesh)       # (B,Lm,H)
   123                                           
   124                                                   # Grid branch: ConvNeXt → (B,Ls,H)
   125                                                   sdf_tokens = self.grid(sdf)                     # (B,Ls,H)
   126                                           
   127                                                   # Concat and process
   128                                                   tokens = torch.cat([mesh_tokens, sdf_tokens], dim=1)  # (B,Lm+Ls,H)
   129                                                   latent = self.approximator(tokens)                    # (B,Lm+Ls,H)
   130                                           
   131                                                   # Decode to per-vertex pressures (queries = raw xyz)
   132                                                   pred = self.decoder(latent, mesh_pos)                 # (B,P,1)
   133                                                   return pred.squeeze(-1)                               # (B,P)

Total time: 6.1134 s
File: /u/l/lfratteg/upt_project/models/model.py
Function: UPT.forward at line 216

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   216                                               @profile
   217                                               def forward(self, mesh_pos: torch.Tensor) -> torch.Tensor:
   218                                                   # Mesh branch: pos-embed (B,P,H) → Perceiver (B,Lm,H)
   219       189    4875954.2  25798.7     79.8          q_mesh = self.mesh_pos_emb(mesh_pos)            # (B,P,H)
   220       189     120632.2    638.3      2.0          tokens = self.mesh_perceiver(q_mesh)       # (B,Lm,H)
   221                                           
   222                                                   # Concat and process
   223       189     950816.3   5030.8     15.6          latent = self.approximator(tokens)                    # (B,Lm+Ls,H)
   224                                           
   225                                                   # Decode to per-vertex pressures (queries = raw xyz)
   226       189     165025.7    873.2      2.7          pred = self.decoder(latent, mesh_pos)                 # (B,P,1)
   227       189        975.8      5.2      0.0          return pred.squeeze(-1)                               # (B,P)

Total time: 0.00215472 s
File: /u/l/lfratteg/upt_project/utils/loader.py
Function: ShapeNetCarDataset.__getitem__ at line 125

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   125                                               @profile
   126                                               def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
   127       189       2154.7     11.4    100.0          return self.mesh[idx], self.pressure[idx], self.sdf[idx]

Total time: 0.0573953 s
File: /u/l/lfratteg/upt_project/utils/utils.py
Function: load_config at line 17

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    17                                           @profile
    18                                           def load_config(path: PathLike) -> Dict[str, Any]:
    19                                               """Load a YAML config file into a Python dict (top-level must be a mapping)."""
    20         1        182.5    182.5      0.3      p = Path(path)
    21         1         91.9     91.9      0.2      if not p.exists():
    22                                                   raise FileNotFoundError(f"Config not found: {p}")
    23         2       1298.3    649.2      2.3      with p.open("r") as f:
    24         1      55816.9  55816.9     97.2          cfg = yaml.safe_load(f)
    25         1          1.6      1.6      0.0      if cfg is None:
    26                                                   return {}
    27         1          3.1      3.1      0.0      if not isinstance(cfg, dict):
    28                                                   raise ValueError("Top-level YAML must be a mapping (key: value).")
    29         1          1.1      1.1      0.0      return cfg

Total time: 0.000896125 s
File: /u/l/lfratteg/upt_project/utils/utils.py
Function: resolve_path at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           @profile
    32                                           def resolve_path(p: PathLike | None, base_dir: Path) -> Path | None:
    33                                               """
    34                                               Expand ~ and $VARS; if relative, resolve relative to base_dir.
    35                                               Returns None if input is None.
    36                                               """
    37         1          1.9      1.9      0.2      if p is None:
    38                                                   return None
    39         1         90.6     90.6     10.1      q = Path(os.path.expandvars(os.path.expanduser(str(p))))
    40         1        803.6    803.6     89.7      return q if q.is_absolute() else (base_dir / q).resolve()

