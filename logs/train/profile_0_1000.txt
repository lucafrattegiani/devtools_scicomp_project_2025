Timer unit: 1e-06 s

Total time: 12.7048 s
File: /u/l/lfratteg/upt_project/models/approximator.py
Function: Approximator.forward at line 76

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    76                                               @profile
    77                                               def forward(self, x: torch.Tensor) -> torch.Tensor:
    78                                                   r"""
    79                                                   Apply the Transformer stack.
    80                                           
    81                                                   Parameters
    82                                                   ----------
    83                                                   x : torch.Tensor
    84                                                       Input tokens of shape ``(B, N, dim)``.
    85                                           
    86                                                   Returns
    87                                                   -------
    88                                                   torch.Tensor
    89                                                       Output tokens of shape ``(B, N, dim)``.
    90                                           
    91                                                   Raises
    92                                                   ------
    93                                                   AssertionError
    94                                                       If ``x`` is not rank-3.
    95                                                   """
    96      2200       2793.7      1.3      0.0          assert x.ndim == 3, f"expected (B, N, dim), got {tuple(x.shape)}"
    97     28600      33369.0      1.2      0.3          for blk in self.blocks:
    98     26400   12668018.7    479.8     99.7              x = blk(x)
    99      2200        665.9      0.3      0.0          return x

Total time: 2.48036 s
File: /u/l/lfratteg/upt_project/models/decoder.py
Function: PerceiverDecoder.forward at line 120

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   120                                               @profile
   121                                               def forward(self, latent: torch.Tensor, queries: torch.Tensor) -> torch.Tensor:
   122                                                   r"""
   123                                                   Project queries to ``H``, run cross-attention with latent as K/V, refine with FFN, and map to scalars.
   124                                           
   125                                                   Parameters
   126                                                   ----------
   127                                                   latent : torch.Tensor
   128                                                       Latent tokens of shape ``(B, T, H)``.
   129                                                   queries : torch.Tensor
   130                                                       Embedded query tokens of shape ``(B, K, H_q)``.
   131                                           
   132                                                   Returns
   133                                                   -------
   134                                                   torch.Tensor
   135                                                       Scalar predictions per query: ``(B, K, 1)``.
   136                                                   """
   137      2200       2955.2      1.3      0.1          assert latent.ndim == 3 and queries.ndim == 3, "expected (B,T,H) and (B,K,H_q)"
   138      2200       2856.1      1.3      0.1          B, T, H_lat = latent.shape
   139      2200       1202.2      0.5      0.0          Bq, K, H_q = queries.shape
   140      2200        682.8      0.3      0.0          assert B == Bq, "batch size mismatch between latent and queries"
   141      2200       1032.4      0.5      0.0          assert H_lat == self.dim, f"latent width mismatch: got {H_lat}, expected {self.dim}"
   142                                           
   143                                                   # 1) Project queries to model width H
   144      2200     308811.2    140.4     12.5          q = self.query_proj(queries)                # (B, K, H)
   145                                           
   146                                                   # 2) Cross-attention: Q attends to latent K=V
   147      2200      85668.1     38.9      3.5          qn = self.q_norm(q)
   148      2200      68779.0     31.3      2.8          kv = self.kv_norm(latent)
   149      2200     892437.0    405.7     36.0          attn_out, _ = self.attn(qn, kv, kv, need_weights=False)   # (B, K, H)
   150      2200      90791.3     41.3      3.7          x = q + self.drop(attn_out)                               # residual
   151                                           
   152                                                   # 3) Feed-forward on the query pathway
   153      2200     402137.5    182.8     16.2          y = self.ffn(self.ffn_norm(x))
   154      2200      30817.9     14.0      1.2          x = x + y                                                 # residual
   155                                           
   156                                                   # 4) Pointwise projection to scalar pressure
   157      2200     591395.6    268.8     23.8          out = self.head(x)                                        # (B, K, 1)
   158      2200        794.3      0.4      0.0          return out

Total time: 0.659866 s
File: /u/l/lfratteg/upt_project/models/encoder.py
Function: PositionalEmbedding.forward at line 112

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   112                                               @profile
   113                                               def forward(self, positions: torch.Tensor) -> torch.Tensor:
   114                                                   r"""
   115                                                   Embed rescaled 3D positions.
   116                                           
   117                                           
   118                                                   Parameters
   119                                                   ----------
   120                                                   positions : torch.Tensor
   121                                                   Coordinates with shape ``(B, K, 3)`` or ``(K, 3)``.
   122                                           
   123                                           
   124                                                   Returns
   125                                                   -------
   126                                                   torch.Tensor
   127                                                   Positional embeddings of shape ``(B, K, H)``.
   128                                                   """
   129                                                   # Adjust dimensions if one sample only is provided
   130      2200       2992.7      1.4      0.5          if positions.dim() == 2:  # (K,3) -> (1,K,3)
   131                                                       positions = positions.unsqueeze(0)
   132                                                   
   133                                                   # Rescale
   134      2200     292318.3    132.9     44.3          x = self.rescale(positions, hi=self.upper, eps=self.eps)
   135                                           
   136                                                   # Apply positional encoding
   137      2200     364554.8    165.7     55.2          return self.pe(x)  # Expect (B, K, H)

Total time: 1.60473 s
File: /u/l/lfratteg/upt_project/models/encoder.py
Function: PerceiverEncoder.forward at line 202

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   202                                               @profile
   203                                               def forward(self, tokens: torch.Tensor) -> torch.Tensor:
   204                                                   r"""
   205                                                   Apply one Perceiver pooling step.
   206                                           
   207                                           
   208                                                   Parameters
   209                                                   ----------
   210                                                   tokens : torch.Tensor
   211                                                   Input token set of shape ``(B, K, H)``.
   212                                           
   213                                           
   214                                                   Returns
   215                                                   -------
   216                                                   torch.Tensor
   217                                                   Latent/query tokens of shape ``(B, L, H)``.
   218                                                   """
   219                                           
   220                                                   # Assert valid input dimensions
   221      2200       2782.1      1.3      0.2          assert tokens.ndim == 3, f"expected (B,K,H), got {tuple(tokens.shape)}"
   222      2200       2002.9      0.9      0.1          B, K, H = tokens.shape
   223      2200       1392.3      0.6      0.1          assert H == self.dim, f"hidden_dim mismatch: tokens H={H}, expected {self.dim}"
   224                                           
   225                                                   # Single Perceiver pooling step
   226      2200    1556632.6    707.6     97.0          Z = self.block(kv=tokens)   # Shape (B, L, H)
   227                                           
   228                                                   # Add grid type embedding
   229      2200       7724.7      3.5      0.5          if self.type_token is not None:
   230      2200      33410.9     15.2      2.1              Z = Z + self.type_token
   231                                           
   232      2200        789.5      0.4      0.0          return Z

Total time: 0 s
File: /u/l/lfratteg/upt_project/models/encoder.py
Function: ConvNeXtEncoder.forward at line 346

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   346                                               @profile
   347                                               def forward(self, sdf: torch.Tensor) -> torch.Tensor:
   348                                                   r"""
   349                                                   Encode an SDF grid into grid tokens.
   350                                           
   351                                           
   352                                                   Parameters
   353                                                   ----------
   354                                                   sdf : torch.Tensor
   355                                                   SDF values with shape ``(B, R, R, R)`` where ``R == resolution``.
   356                                           
   357                                           
   358                                                   Returns
   359                                                   -------
   360                                                   torch.Tensor
   361                                                   Grid tokens of shape ``(B, T, H)``.
   362                                                   """
   363                                                   # Validate shape and resolution
   364                                                   assert sdf.ndim == 4, f"expected (B,R,R,R), got {tuple(sdf.shape)}"
   365                                                   B, Rx, Ry, Rz = sdf.shape
   366                                                   assert Rx == Ry == Rz == self.resolution, (
   367                                                       f"expected cubic grid with side={self.resolution}, got {(Rx, Ry, Rz)}"
   368                                                   )
   369                                           
   370                                                   # 1) Add channel axis for 3D convs (channels-first)  
   371                                                   x = sdf.unsqueeze(1)                                   # (B, 1, R, R, R)
   372                                           
   373                                                   # 2) Apply ConvNeXt-v2
   374                                                   x = self.model(x)                                      # (B, H, S, S, S), S=self.out_side
   375                                           
   376                                                   # 3) Flatten spatial grid into tokens
   377                                                   tokens = einops.rearrange(x, "b c d h w -> b (d h w) c")  # (B, T, H), T = S*S*S
   378                                           
   379                                                   # 4) Add grid type embedding (broadcast add)
   380                                                   if self.type_token is not None:
   381                                                       tokens = tokens + self.type_token                   # (B, T, H)
   382                                           
   383                                                   return tokens

Total time: 0 s
File: /u/l/lfratteg/upt_project/models/model.py
Function: UPTSDF.forward at line 118

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   118                                               @profile
   119                                               def forward(self, mesh_pos: torch.Tensor, sdf: torch.Tensor) -> torch.Tensor:
   120                                                   # Mesh branch: pos-embed (B,P,H) → Perceiver (B,Lm,H)
   121                                                   q_mesh = self.mesh_pos_emb(mesh_pos)            # (B,P,H)
   122                                                   mesh_tokens = self.mesh_perceiver(q_mesh)       # (B,Lm,H)
   123                                           
   124                                                   # Grid branch: ConvNeXt → (B,Ls,H)
   125                                                   sdf_tokens = self.grid(sdf)                     # (B,Ls,H)
   126                                           
   127                                                   # Concat and process
   128                                                   tokens = torch.cat([mesh_tokens, sdf_tokens], dim=1)  # (B,Lm+Ls,H)
   129                                                   latent = self.approximator(tokens)                    # (B,Lm+Ls,H)
   130                                           
   131                                                   # Decode to per-vertex pressures (queries = raw xyz)
   132                                                   pred = self.decoder(latent, mesh_pos)                 # (B,P,1)
   133                                                   return pred.squeeze(-1)                               # (B,P)

Total time: 17.7097 s
File: /u/l/lfratteg/upt_project/models/model.py
Function: UPT.forward at line 216

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   216                                               @profile
   217                                               def forward(self, mesh_pos: torch.Tensor) -> torch.Tensor:
   218                                                   # Mesh branch: pos-embed (B,P,H) → Perceiver (B,Lm,H)
   219      2200     710619.7    323.0      4.0          q_mesh = self.mesh_pos_emb(mesh_pos)            # (B,P,H)
   220      2200    1653416.7    751.6      9.3          tokens = self.mesh_perceiver(q_mesh)       # (B,Lm,H)
   221                                           
   222                                                   # Concat and process
   223      2200   12784345.1   5811.1     72.2          latent = self.approximator(tokens)                    # (B,Lm+Ls,H)
   224                                           
   225                                                   # Decode to per-vertex pressures (queries = raw xyz)
   226      2200    2547348.1   1157.9     14.4          pred = self.decoder(latent, mesh_pos)                 # (B,P,1)
   227      2200      14004.7      6.4      0.1          return pred.squeeze(-1)                               # (B,P)

Total time: 0.381615 s
File: /u/l/lfratteg/upt_project/utils/loader.py
Function: ShapeNetCarDataset.__getitem__ at line 125

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   125                                               @profile
   126                                               def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
   127     70000     381615.5      5.5    100.0          return self.mesh[idx], self.pressure[idx], self.sdf[idx]

Total time: 0.0583464 s
File: /u/l/lfratteg/upt_project/utils/utils.py
Function: load_config at line 17

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    17                                           @profile
    18                                           def load_config(path: PathLike) -> Dict[str, Any]:
    19                                               """Load a YAML config file into a Python dict (top-level must be a mapping)."""
    20         1        191.0    191.0      0.3      p = Path(path)
    21         1         73.0     73.0      0.1      if not p.exists():
    22                                                   raise FileNotFoundError(f"Config not found: {p}")
    23         2       1335.1    667.6      2.3      with p.open("r") as f:
    24         1      56742.5  56742.5     97.3          cfg = yaml.safe_load(f)
    25         1          1.2      1.2      0.0      if cfg is None:
    26                                                   return {}
    27         1          2.5      2.5      0.0      if not isinstance(cfg, dict):
    28                                                   raise ValueError("Top-level YAML must be a mapping (key: value).")
    29         1          1.0      1.0      0.0      return cfg

Total time: 0.00109244 s
File: /u/l/lfratteg/upt_project/utils/utils.py
Function: resolve_path at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           @profile
    32                                           def resolve_path(p: PathLike | None, base_dir: Path) -> Path | None:
    33                                               """
    34                                               Expand ~ and $VARS; if relative, resolve relative to base_dir.
    35                                               Returns None if input is None.
    36                                               """
    37         1          2.1      2.1      0.2      if p is None:
    38                                                   return None
    39         1         87.0     87.0      8.0      q = Path(os.path.expandvars(os.path.expanduser(str(p))))
    40         1       1003.3   1003.3     91.8      return q if q.is_absolute() else (base_dir / q).resolve()

